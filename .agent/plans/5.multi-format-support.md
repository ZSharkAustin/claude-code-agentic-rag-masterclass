# Module 5: Multi-Format Support

⚠️ **Medium** - Pipeline refactor with new dependency; may need iteration on docling API usage

## Summary

Add DOCX and HTML support via docling, switch to document-aware chunking, fix cascade delete reliability. Keep pypdf as PDF fallback.

## Files to Modify

| File | Changes |
|------|---------|
| `backend/requirements.txt` | Add `docling` dependency |
| `backend/app/services/document_service.py` | Replace `_extract_text` + `_chunk_text` with docling-based pipeline |
| `backend/app/routers/documents.py` | Expand MIME types, MIME normalization, fix delete order |
| `frontend/src/pages/DocumentsPage.tsx` | Update file input accept + empty state text |
| `PROGRESS.md` | Add Module 5 section |

---

## Phase 1: Dependency Setup

### 1.1 Add docling dependency
- **File:** `backend/requirements.txt`
- Add `docling>=2.0.0` (keep `pypdf>=5.0.0`)
- **Validate:** `pip install -r requirements.txt` then `python -c "from docling.document_converter import DocumentConverter; from docling_core.transforms.chunker import HierarchicalChunker; print('OK')"`
- **Note:** docling is heavy (includes ML models). First install may pull significant dependencies.

---

## Phase 2: Refactor Document Processing Pipeline

All changes in `backend/app/services/document_service.py`.

### 2.1 Add `_convert_document()` — replaces `_extract_text()`

New function using docling's `DocumentConverter`:
- PDF, DOCX, HTML, Markdown → `DocumentConverter.convert()` → returns `DoclingDocument`
- TXT → direct UTF-8 decode → returns `str`
- PDF fallback: if docling fails, fall back to pypdf (`_extract_text_pypdf()`)
- Lazy-init singleton `DocumentConverter` via `_get_converter()` (expensive to create)
- Use `DocumentStream(name=filename, stream=BytesIO(file_bytes))` — `name` must include file extension for format detection

### 2.2 Add `_chunk_document()` — replaces `_chunk_text()`

Dual-path chunking:
- `DoclingDocument` input → `HierarchicalChunker().chunk()` → extract `.text` from each chunk
- `str` input (TXT or pypdf fallback) → sliding window (keep existing `CHUNK_SIZE=1000`, `CHUNK_OVERLAP=200`)

### 2.3 Update `process_document()` orchestrator

Replace lines 72-78:
```
# Old
text = _extract_text(file_bytes, mime_type)
chunks = _chunk_text(text)

# New
doc_or_text = _convert_document(file_bytes, mime_type, filename)
text = doc_or_text if isinstance(doc_or_text, str) else doc_or_text.export_to_text()
chunks = _chunk_document(doc_or_text)
```
Rest of pipeline (metadata extraction, embedding, chunk storage) unchanged — both `text` and `chunks` are still strings.

### 2.4 Clean up
- Remove old `_extract_text()` and `_chunk_text()` functions
- Keep `_extract_text_pypdf()` as the new fallback function (extracted from old `_extract_text`)
- Keep constants (`CHUNK_SIZE`, `CHUNK_OVERLAP`) — still used by sliding window fallback

**Validate:** Upload a PDF, TXT file → both process to "ready" with chunks.

---

## Phase 3: Expand Supported File Types

### 3.1 Update router MIME types
- **File:** `backend/app/routers/documents.py` line 15
- Add to `ALLOWED_MIME_TYPES`:
  - `"application/vnd.openxmlformats-officedocument.wordprocessingml.document"`
  - `"text/html"`
- Add MIME normalization after existing `.md` handler (line 29-30):
  - `.docx` → `application/vnd.openxmlformats-officedocument.wordprocessingml.document`
  - `.html`/`.htm` → `text/html`
- Update error message (line 34): `"Allowed: PDF, TXT, MD, DOCX, HTML"`

**Validate:** Upload `.docx` and `.html` files → accepted (not 400). Upload `.zip` → still rejected.

### 3.2 Update frontend file input
- **File:** `frontend/src/pages/DocumentsPage.tsx`
- Line 61: `accept=".pdf,.txt,.md,.docx,.html,.htm"`
- Line 91: `"No documents uploaded yet. Upload a PDF, DOCX, TXT, HTML, or MD file to get started."`

**Validate:** File picker shows new file types. Empty state message updated.

---

## Phase 4: Fix Cascade Delete

### 4.1 Reorder delete: DB first, then best-effort storage cleanup
- **File:** `backend/app/routers/documents.py` lines 123-150
- Currently: storage delete → DB delete (if storage fails, DB record is left with no file)
- New order: DB delete first (chunks cascade via FK) → then try storage delete in try/except
- If storage delete fails, log warning but return 204 anyway (orphaned file is harmless)
- Add `import logging` + `logger = logging.getLogger(__name__)` at top

**Validate:** Delete a document → DB record and chunks gone. Simulate storage failure → still returns 204.

---

## Phase 5: Update Progress

### 5.1 Update PROGRESS.md
Add Module 5 section with all completed tasks.

---

## End-to-End Validation

1. Start backend: `cd backend && source venv/bin/activate && uvicorn app.main:app --reload`
2. Start frontend: `cd frontend && npm run dev`
3. Upload each format and verify "ready" status:
   - `.pdf` — should use docling (or pypdf fallback)
   - `.docx` — new format via docling
   - `.html` — new format via docling
   - `.txt` — direct text decode + sliding window chunks
   - `.md` — docling conversion + hierarchical chunks
4. Chat and ask questions about uploaded documents → verify RAG search still works
5. Delete a document → verify DB record, chunks, and storage file are all gone
6. Check LangSmith traces for the processing pipeline

## Risks

- **docling install size:** Heavy ML deps. May need `docling-core` only if full docling is too large.
- **HierarchicalChunker chunk sizes:** Non-uniform. Some chunks may be very short or long. If quality is poor, consider `HybridChunker` (requires tokenizer config).
- **`export_to_text()` availability:** If this method doesn't exist on DoclingDocument, use `export_to_markdown()` as alternative for metadata extraction input.
- **Concurrency:** Module-level `_converter` singleton isn't thread-safe. FastAPI BackgroundTasks share thread pool. Use a lock if concurrent processing causes issues.
